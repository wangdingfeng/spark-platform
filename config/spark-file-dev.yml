spring:
  cloud:
    nacos:
      discovery:
        ip: 127.0.0.1
        port: ${server.port}
  servlet:
    multipart:
      enabled: true
      max-file-size: 50MB
      max-request-size: 100MB
  jackson:
    default-property-inclusion: non_null
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://127.0.0.1:3306/spark-dev?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=GMT%2B8
    username: root
    password: 123456
    name: spark-dev
    type: com.alibaba.druid.pool.DruidDataSource
    initial-size: 5
    min-idle: 5
    max-active: 20
    max-wait: 30000
    time-between-eviction-runs-millis: 60000
    min-evictable-idle-time-millis: 300000
    validation-query: select '1' from dual
    test-while-idle: true
    test-on-borrow: false
    test-on-return: false
    pool-prepared-statements: true
    max-open-prepared-statements: 20
    max-pool-prepared-statement-per-connection-size: 20
    filters: stat,wall
  boot:
    admin:
      client:
        url: http://127.0.0.1:9002
        instance:
          prefer-ip: true
          service-url: http://${spring.cloud.nacos.discovery.ip}:${spring.cloud.nacos.discovery.port}
        username: spark
        password: spark
  redis:
    host: 127.0.0.1
    port: 6379
    timeout: 10000
    database: 0
    password:
    lettuce:
      pool:
        max-active: 300
        max-idle: 100
        max-wait: -1
        min-idle: 20
      shutdown-timeout: 10000

mybatis-plus:
  mapper-locations: classpath*:mapper/*.xml
  type-aliases-package: com.spark.plateform.file.api.entity
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
    cache-enabled: false
    map-underscore-to-camel-case: true
    use-generated-keys: true
    default-executor-type: reuse
    defaultStatementTimeout: 1000
    jdbc-type-for-null: null
    call-setters-on-nulls: true

management:
  metrics:
    web:
      server:
        auto-time-requests: false
  endpoints:
    web:
      exposure:
        include: "*"
  endpoint:
    bus-refresh:
      enabled: true

swagger:
  base-package: com.spark.platform.file
  enabled: true
  description: Spark 文件服务
  version: V1.0
  license: Apache License, Version 2.0
  license-url: https://www.apache.org/licenses/LICENSE-2.0.html
  authorization:
    key-name: Authorization
  contact:
    name: wangdingfeng
    email: wangdingfeng@live.com

minio:
  endpoint: 127.0.0.1
  port: 9000
  accessKey: minioadmin
  secretKey: minioadmin
  secure: false
  bucketName: "spark"

ribbon:
  ReadTimeout: 10000
  ConnectTimeout: 5000
  MaxAutoRetries: 1
  MaxAutoRetriesNextServer: 2
  eureka:
    enabled: true

feign:
  sentinel:
    enabled: true
  okhttp:
    enabled: true
  httpclient:
    enabled: false

spark:
  ignore:
    urls:
      - /actuator/**
      - /druid/**
      - /**/api/**
      - /v2/api-docs
      - /swagger-ui.html
      - /swagger-resources/**
      - /webjars/**
  file-path: E:/spark/file